# DINOv3 Zero-Shot Segmentation Notebook

DINOv3の特徴を使用したインタラクティブな零ショットセグメンテーションのGoogle Colabノートブック

## 概要

このノートブックは、Meta AI Researchが開発したDINOv3（Vision Transformer）モデルを使用して、画像内の任意の領域を零ショットでセグメンテーションする方法を示します。ユーザーが画像上でクリックした点（シードポイント）を基準に、視覚的に類似した領域を自動的に抽出します。

## 主な機能

### 1. インタラクティブな画像処理
- **画像アップロード**: ローカルファイルから簡単に画像をアップロード
- **シードポイント選択**: 画像を直接クリックして関心領域を指定
- **リアルタイムフィードバック**: 選択した点が即座に可視化される

### 2. 高度なAIモデル
- **DINOv3 ViT-L/16**: 1024次元の高品質な特徴ベクトルを使用
- **24層のTransformer**: 深い意味的理解が可能
- **16x16パッチサイズ**: 詳細な空間情報を保持

### 3. 柔軟なセグメンテーション
- **コサイン類似度計算**: シードパッチと全パッチ間の類似度を計算
- **インタラクティブ閾値調整**: スライダーでリアルタイムに結果を調整
- **マルチビュー可視化**: オリジナル、類似度マップ、セグメンテーション結果を同時表示

### 4. 結果の保存
- セグメンテーションマスクのエクスポート
- 類似度ヒートマップの保存
- オーバーレイ画像の出力

## 使用方法

### 1. Google Colabで開く
ノートブックの上部にある「Open in Colab」バッジをクリックしてGoogle Colabで開きます。

### 2. セルを順番に実行
1. **環境セットアップ**: 必要なライブラリをインストール
2. **モデル読み込み**: DINOv3 ViT-L/16モデルを読み込む（初回は時間がかかります）
3. **ヘルパー関数定義**: 画像処理と特徴抽出の関数を定義

### 3. 画像をアップロード
- ファイル選択ダイアログから画像を選択
- 画像は自動的にパッチサイズに合わせてリサイズされます
- アスペクト比は維持されます

### 4. DINOv3特徴を抽出
- GPU上で自動的に特徴抽出が実行されます
- 1024次元の特徴ベクトルが各16x16パッチに対して生成されます

### 5. シードポイントを選択
- 表示された画像上でセグメンテーションしたい領域をクリック
- 赤い円が選択した点を示します
- 赤い四角が対応する16x16パッチの範囲を示します

### 6. 類似度を計算
- シードパッチの特徴と全パッチの特徴間のコサイン類似度を計算
- 類似度マップがヒートマップとして表示されます

### 7. 閾値を調整してセグメンテーション
- スライダーを動かして類似度の閾値を調整（-1.0から1.0）
- リアルタイムで以下が更新されます：
  - 類似度マップ（カラーバー上の赤線が現在の閾値を示す）
  - バイナリマスク（白が選択領域）
  - オーバーレイ画像
  - セグメンテーション結果

### 8. 結果を保存（オプション）
- 最終セルを実行して結果を画像ファイルとして保存
- 自動的にダウンロードされます

## 技術詳細

### モデルアーキテクチャ
- **ベースモデル**: DINOv3 ViT-L/16
- **パッチサイズ**: 16x16ピクセル
- **特徴次元**: 1024
- **レイヤー数**: 24
- **正規化**: ImageNet統計値による正規化

### 特徴抽出
- 最終層の出力特徴を使用
- 各パッチは1024次元のベクトルで表現
- L2正規化により方向のみを考慮（コサイン類似度用）

### セグメンテーション手法
1. シードポイントから対応するパッチ座標を計算
2. シードパッチの特徴ベクトルを抽出
3. 全パッチとのコサイン類似度を計算
4. 類似度マップを元の画像サイズにアップサンプリング
5. 閾値処理でバイナリマスクを生成
6. ガウシアンスムージングで見た目を改善

### 可視化
- **類似度マップ**: Viridisカラーマップで-1から1の範囲を表示
- **セグメンテーションマスク**: グレースケールで0から1の範囲を表示
- **オーバーレイ**: 元画像に半透明のマスクを重ねて表示
- **セグメンテーション結果**: マスク領域のみを抽出して表示

## 利点

### 零ショット学習
- **学習不要**: 特定のデータセットで学習する必要なし
- **汎用性**: あらゆる種類の画像に適用可能
- **即座に使用可能**: モデルをダウンロードするだけで使用開始

### インタラクティブ性
- **リアルタイムフィードバック**: スライダーで即座に結果が更新
- **直感的な操作**: クリックするだけでシード点を指定
- **視覚的な調整**: 複数のビューで結果を確認しながら調整

### 意味的理解
- **DINOv3の表現力**: 深い意味的特徴を活用
- **視覚的類似性**: 色だけでなく形状や質感も考慮
- **ロバスト性**: 照明やスケールの変化に強い

### 柔軟性
- **閾値調整**: 用途に応じて選択性を変更可能
- **マルチビュー**: 様々な角度から結果を確認
- **結果保存**: PNG形式で簡単に保存・共有

## 使用例

### 物体セグメンテーション
- 写真内の特定の物体（人、動物、車など）をクリックして抽出
- 複雑な背景からでも物体を分離可能

### 領域抽出
- 画像の特定の領域（空、草原、建物など）を選択
- 類似したテクスチャや色の領域を自動的に見つける

### 前景分離
- 主要な被写体をクリックして背景から分離
- ポートレート写真の処理などに有用

## システム要件

- **Google Colab環境**: 無料版で実行可能
- **GPU推奨**: T4 GPU以上（無料版で利用可能）
- **メモリ**: 標準的なColab環境で十分
- **インターネット接続**: モデルのダウンロードに必要

## 制限事項

- パッチサイズ（16x16）による空間解像度の制約
- 非常に小さな物体や細い線の検出には不向き
- 処理速度は画像サイズとGPUに依存
- 最初の実行時はモデルダウンロードに時間がかかる

## 今後の拡張可能性

### 機能拡張
- **複数シードポイント**: 複数の点から同時にセグメンテーション
- **マルチスケール処理**: 異なる解像度での特徴を統合
- **後処理**: CRFやGrabCutとの組み合わせ

### 応用
- **物体検出との統合**: バウンディングボックスからの自動セグメンテーション
- **ビデオセグメンテーション**: 時系列情報を活用した追跡
- **インタラクティブ編集**: 画像編集ツールへの組み込み

## 参考文献

- [DINOv3: Learning Robust Visual Features without Supervision](https://arxiv.org/abs/2304.07193)
- [Facebook Research DINOv3 GitHub Repository](https://github.com/facebookresearch/dinov3)

## ライセンス

このノートブックはDINOv3の公式実装を基にしています。DINOv3のライセンス条項に従ってください。

## 貢献

バグ報告や機能提案は、GitHubのIssuesセクションでお願いします。

## 作成者

Created by Devin AI for Ryuichi Nakahara (@okayamatarou)

---

**注意**: このノートブックは教育・研究目的で作成されています。商用利用の際は適切なライセンスを確認してください。
